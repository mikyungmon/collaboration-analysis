{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0We8-Fr3uAv3",
        "outputId": "50b7052e-121f-407d-987a-89416c602350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from konlpy) (5.2.2)\n",
            "Requirement already satisfied: numpy>=1.6 in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\linak\\anaconda3\\envs\\dev4\\lib\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozRVRUSn2fkm"
      },
      "source": [
        "불용어 직접 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuIv4Ruwqunt",
        "outputId": "781c725a-ff5d-41a6-fb85-289accd49fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "키워드: ['그게' '그냥' '그러니까' '그럼' '아니' '우리가' '이거' '이게' '있는' '지금']\n",
            "중요 발언자 순위:\n",
            "SPEAKER_03: 137.62333108296826\n",
            "SPEAKER_00: 62.55116139915662\n",
            "SPEAKER_01: 45.53221583225188\n",
            "SPEAKER_04: 35.57577190386088\n",
            "SPEAKER_02: 2.0\n",
            "\n",
            "키워드 빈도 데이터프레임:\n",
            "                  그게         그냥       그러니까        그럼         아니       우리가  \\\n",
            "Speaker                                                                     \n",
            "SPEAKER_00  2.476825   8.573756   6.876987  6.831557   6.760044  5.918792   \n",
            "SPEAKER_01  4.773924   7.694423  11.672553  4.516351   1.000000  1.745748   \n",
            "SPEAKER_02  0.000000   1.000000   0.000000  0.000000   0.000000  0.000000   \n",
            "SPEAKER_03  8.478022  13.947390  15.806804  3.808463  11.432373  9.688905   \n",
            "SPEAKER_04  3.000000   3.897552   1.000000  7.712852   3.000000  3.751569   \n",
            "\n",
            "                   이거         이게        있는         지금  \n",
            "Speaker                                                \n",
            "SPEAKER_00   7.255762   6.094259  6.126800   5.636379  \n",
            "SPEAKER_01   3.548846   1.698652  3.260756   5.620962  \n",
            "SPEAKER_02   0.000000   1.000000  0.000000   0.000000  \n",
            "SPEAKER_03  25.259063  20.773064  6.564775  21.864473  \n",
            "SPEAKER_04   3.000000   3.766283  5.447516   1.000000  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def load_and_preprocess(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    data = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        speaker_line = lines[i].strip()\n",
        "        content_line = lines[i+1].strip() if i+1 < len(lines) else \"\"\n",
        "\n",
        "        # 발화자 정보가 'Speaker'로 시작하는지 확인\n",
        "        if speaker_line.startswith('Speaker'):\n",
        "            speaker_info = speaker_line.split()\n",
        "            if len(speaker_info) >= 3:\n",
        "                speaker = speaker_info[1]\n",
        "                time = speaker_info[2]\n",
        "\n",
        "                data.append([speaker, time, content_line])\n",
        "\n",
        "        i += 2\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['Speaker', 'Time', 'Content'])\n",
        "    return df\n",
        "\n",
        "# 사용자 정의 한국어 불용어 목록\n",
        "korean_stop_words = [\n",
        "    '그', '그래서', '그러나', '그리고', '이', '저', '것', '등', '더', '수', '등등', '하지만', '그리고', '다시', '때문에', '이제', '저희', '그런', '저희가', '제가', '근데', '너무', '이런', '이렇게', '저는', '저도', '좋아요', '하고', '하는', '혹시'\n",
        "]\n",
        "\n",
        "# 데이터 로드 (원하는 파일 경로로 수정)\n",
        "file_path = 'transcriptions/project4/transcription_project4_09.txt'\n",
        "df = load_and_preprocess(file_path)\n",
        "\n",
        "# TF-IDF 벡터라이저 초기화\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10, stop_words=korean_stop_words)  # 최대 10개의 키워드를 추출\n",
        "\n",
        "# TF-IDF 행렬 생성\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Content'])\n",
        "\n",
        "# 키워드 확인\n",
        "keywords = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"키워드:\", keywords)\n",
        "\n",
        "# TF-IDF 행렬을 DataFrame으로 변환\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=keywords)\n",
        "\n",
        "# 원본 데이터와 결합\n",
        "df = pd.concat([df, tfidf_df], axis=1)\n",
        "\n",
        "# 각 참가자의 키워드 빈도 합계 계산\n",
        "keyword_freq_by_speaker = df.groupby('Speaker')[keywords].sum()\n",
        "\n",
        "# 중요 발언자 선정\n",
        "important_speakers = keyword_freq_by_speaker.sum(axis=1).sort_values(ascending=False).index.tolist()\n",
        "\n",
        "print(\"중요 발언자 순위:\")\n",
        "for speaker in important_speakers:\n",
        "    print(f\"{speaker}: {keyword_freq_by_speaker.loc[speaker].sum()}\")\n",
        "\n",
        "print(\"\\n키워드 빈도 데이터프레임:\")\n",
        "print(keyword_freq_by_speaker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2c0Vgeg2hXn"
      },
      "source": [
        "불용어 파일 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RhRVpemuHMB",
        "outputId": "d924141e-e0d9-4e1b-f19e-52a1c5412909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "키워드: ['그냥' '생각' '얘기' '이제' '지금']\n",
            "중요 발언자 순위:\n",
            "SPEAKER_03: 96.18115064516562\n",
            "SPEAKER_00: 50.514220906525885\n",
            "SPEAKER_01: 23.41154604699745\n",
            "SPEAKER_04: 10.76984046696314\n",
            "SPEAKER_02: 2.0\n",
            "\n",
            "키워드 빈도 데이터프레임:\n",
            "                   그냥         생각         얘기         이제         지금\n",
            "Speaker                                                          \n",
            "SPEAKER_00  10.000000  10.371457   6.540856  14.611388   8.990521\n",
            "SPEAKER_01   9.000000   3.749183   2.000000   0.000000   8.662363\n",
            "SPEAKER_02   1.000000   0.000000   0.000000   0.000000   1.000000\n",
            "SPEAKER_03  16.480647   7.669751  18.315009  29.879340  23.836403\n",
            "SPEAKER_04   3.552730   4.217110   1.000000   1.000000   1.000000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# 한국어 불용어 목록\n",
        "stopwords_file = 'data/stopwords-ko.txt'\n",
        "\n",
        "with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
        "    stopwords_list = [word.strip() for word in f.readlines()]\n",
        "\n",
        "def load_and_preprocess(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    data = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        speaker_line = lines[i].strip()\n",
        "        content_line = lines[i+1].strip() if i+1 < len(lines) else \"\"\n",
        "\n",
        "        # 발화자 정보가 'Speaker'로 시작하는지 확인\n",
        "        if speaker_line.startswith('Speaker'):\n",
        "            speaker_info = speaker_line.split()\n",
        "            if len(speaker_info) >= 3:\n",
        "                speaker = speaker_info[1]\n",
        "                time = speaker_info[2]\n",
        "\n",
        "                data.append([speaker, time, content_line])\n",
        "\n",
        "        i += 2\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['Speaker', 'Time', 'Content'])\n",
        "    return df\n",
        "\n",
        "# 형태소 분석기를 사용한 전처리 함수\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    okt = Okt()\n",
        "\n",
        "    tokens = okt.nouns(text)\n",
        "    tokens = [token for token in tokens if token not in stopwords_list and len(token) > 1]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "file_path = 'transcriptions/project4/transcription_project4_09.txt'\n",
        "df = load_and_preprocess(file_path)\n",
        "\n",
        "# Content 열에 대해 전처리 수행\n",
        "df['Processed_Content'] = df['Content'].apply(tokenize_and_remove_stopwords)\n",
        "\n",
        "# TF-IDF 벡터라이저 초기화\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5)\n",
        "\n",
        "# TF-IDF 행렬 생성\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Processed_Content'])\n",
        "\n",
        "# 키워드 확인\n",
        "keywords = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"키워드:\", keywords)\n",
        "\n",
        "# TF-IDF 행렬을 DataFrame으로 변환\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=keywords)\n",
        "\n",
        "# 원본 데이터와 결합\n",
        "df = pd.concat([df, tfidf_df], axis=1)\n",
        "\n",
        "# 각 참가자의 키워드 빈도 합계 계산\n",
        "keyword_freq_by_speaker = df.groupby('Speaker')[keywords].sum()\n",
        "\n",
        "# 중요 발언자 선정\n",
        "important_speakers = keyword_freq_by_speaker.sum(axis=1).sort_values(ascending=False).index.tolist()\n",
        "\n",
        "print(\"중요 발언자 순위:\")\n",
        "for speaker in important_speakers:\n",
        "    print(f\"{speaker}: {keyword_freq_by_speaker.loc[speaker].sum()}\")\n",
        "\n",
        "print(\"\\n키워드 빈도 데이터프레임:\")\n",
        "print(keyword_freq_by_speaker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDMaxLBO-Iqx"
      },
      "source": [
        "키워드 직접 입력 및 검색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi89dDNkv-hh",
        "outputId": "4088391e-2fc7-456d-94d3-2ab83097c104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "중요 발언자 순위:\n",
            "SPEAKER_03: 10 회\n",
            "SPEAKER_00: 9 회\n",
            "SPEAKER_04: 7 회\n",
            "SPEAKER_01: 1 회\n",
            "SPEAKER_02: 1 회\n",
            "\n",
            "각 키워드 사용 횟수 데이터프레임:\n",
            "            협업_Count  외생변수_Count  녹음_Count  HR_Count  부서를_Count  부서별_Count  \\\n",
            "Speaker                                                                      \n",
            "SPEAKER_00         1           1         1         1          0          4   \n",
            "SPEAKER_01         0           1         0         0          0          0   \n",
            "SPEAKER_02         0           0         1         0          0          0   \n",
            "SPEAKER_03         2           1         3         0          0          1   \n",
            "SPEAKER_04         0           0         2         1          0          1   \n",
            "\n",
            "            시각화_Count  테스트_Count  ab_Count  \n",
            "Speaker                                     \n",
            "SPEAKER_00          1          0         0  \n",
            "SPEAKER_01          0          0         0  \n",
            "SPEAKER_02          0          0         0  \n",
            "SPEAKER_03          0          1         2  \n",
            "SPEAKER_04          0          2         1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    data = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        speaker_line = lines[i].strip()\n",
        "        content_line = lines[i+1].strip() if i+1 < len(lines) else \"\"\n",
        "\n",
        "        # 발화자 정보가 'Speaker'로 시작하는지 확인\n",
        "        if speaker_line.startswith('Speaker'):\n",
        "            speaker_info = speaker_line.split()\n",
        "            if len(speaker_info) >= 3:\n",
        "                speaker = speaker_info[1]\n",
        "                time = speaker_info[2]\n",
        "\n",
        "                data.append([speaker, time, content_line])\n",
        "\n",
        "        i += 2\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['Speaker', 'Time', 'Content'])\n",
        "    return df\n",
        "\n",
        "# 키워드 설정\n",
        "keywords = ['협업', '외생변수', '녹음', 'HR', '부서를', '부서별', '시각화', '테스트', 'ab']\n",
        "\n",
        "file_path = 'transcriptions/project4/transcription_project4_09.txt'\n",
        "df = load_and_preprocess(file_path)\n",
        "\n",
        "# 발언자별로 키워드 사용 횟수 계산\n",
        "for keyword in keywords:\n",
        "    df[keyword + '_Count'] = df['Content'].apply(lambda x: x.count(keyword))\n",
        "\n",
        "# 각 발언자의 키워드 사용 횟수 합계 계산\n",
        "keyword_counts = df.groupby('Speaker')[[keyword + '_Count' for keyword in keywords]].sum()\n",
        "\n",
        "# 키워드별로 중요 발언자 선정\n",
        "important_speakers = keyword_counts.sum(axis=1).sort_values(ascending=False).index.tolist()\n",
        "\n",
        "print(\"중요 발언자 순위:\")\n",
        "for speaker in important_speakers:\n",
        "    total_count = keyword_counts.loc[speaker].sum()\n",
        "    print(f\"{speaker}: {total_count} 회\")\n",
        "\n",
        "print(\"\\n각 키워드 사용 횟수 데이터프레임:\")\n",
        "print(keyword_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We3szygj91s8"
      },
      "source": [
        "findall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPWUkxSo3AzD",
        "outputId": "4e45916a-dbc9-4360-9bc4-9bfe33d59f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "중요 발언자 순위:\n",
            "SPEAKER_00: 4 회\n",
            "SPEAKER_03: 2 회\n",
            "SPEAKER_04: 2 회\n",
            "SPEAKER_01: 1 회\n",
            "SPEAKER_02: 0 회\n",
            "\n",
            "각 키워드 사용 횟수 데이터프레임:\n",
            "            협업_Count  외생변수_Count  HR_Count  부서별_Count  시각화_Count  테스트_Count\n",
            "Speaker                                                                    \n",
            "SPEAKER_00         1           0         1          2          0          0\n",
            "SPEAKER_01         0           1         0          0          0          0\n",
            "SPEAKER_02         0           0         0          0          0          0\n",
            "SPEAKER_03         0           1         0          0          0          1\n",
            "SPEAKER_04         0           0         1          1          0          0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    data = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        speaker_line = lines[i].strip()\n",
        "        content_line = lines[i+1].strip() if i+1 < len(lines) else \"\"\n",
        "\n",
        "        # 발화자 정보가 'Speaker'로 시작하는지 확인\n",
        "        if speaker_line.startswith('Speaker'):\n",
        "            speaker_info = speaker_line.split()\n",
        "            if len(speaker_info) >= 3:\n",
        "                speaker = speaker_info[1]\n",
        "                time = speaker_info[2]\n",
        "\n",
        "                data.append([speaker, time, content_line])\n",
        "\n",
        "        i += 2\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['Speaker', 'Time', 'Content'])\n",
        "    return df\n",
        "\n",
        "# 키워드 설정\n",
        "keywords = ['협업', '외생변수', 'HR', '부서별', '시각화', '테스트']\n",
        "\n",
        "file_path = 'transcriptions/project4/transcription_project4_09.txt'\n",
        "df = load_and_preprocess(file_path)\n",
        "\n",
        "# 발언자별로 키워드 사용 횟수 계산 (정규표현식 사용)\n",
        "for keyword in keywords:\n",
        "    df[keyword + '_Count'] = df['Content'].apply(lambda x: len(re.findall(r'\\b{}\\b'.format(re.escape(keyword)), x, re.IGNORECASE)))\n",
        "\n",
        "# 각 발언자의 키워드 사용 횟수 합계 계산\n",
        "keyword_counts = df.groupby('Speaker')[[keyword + '_Count' for keyword in keywords]].sum()\n",
        "\n",
        "# 키워드별로 중요 발언자 선정\n",
        "important_speakers = keyword_counts.sum(axis=1).sort_values(ascending=False).index.tolist()\n",
        "\n",
        "print(\"중요 발언자 순위:\")\n",
        "for speaker in important_speakers:\n",
        "    total_count = keyword_counts.loc[speaker].sum()\n",
        "    print(f\"{speaker}: {total_count} 회\")\n",
        "\n",
        "print(\"\\n각 키워드 사용 횟수 데이터프레임:\")\n",
        "print(keyword_counts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
